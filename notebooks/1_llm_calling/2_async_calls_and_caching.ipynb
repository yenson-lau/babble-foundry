{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a3d7ff",
   "metadata": {},
   "source": [
    "## Advanced LLM Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b9fedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from babble_foundry.openrouter import OpenRouter\n",
    "\n",
    "display(load_dotenv(override=True))\n",
    "\n",
    "client = OpenRouter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae059dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def get_elapsed(self, verbose: bool = False) -> float:\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        if verbose:\n",
    "            print(f\"{time.time() - self.start_time:.2f} seconds elapsed\")\n",
    "        return elapsed_time\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db086cf",
   "metadata": {},
   "source": [
    "### Asynchronous calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf8af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21 seconds elapsed\n",
      "\n",
      " 1. Kensington Market: Vibrant, eclectic neighborhood with unique shops, street performers, and cultural food choices.\n",
      "2. Parks: High Park, Trinity Bellwoods Park, andAllan Gardens offer a casual setting for socializing.\n",
      "3. Meetup.com: Various groups for interests such as sports, hobbies, and networking meet regularly.\n",
      "4. Toronto Public Library: Attend free events, programs, and workshops.\n",
      "5. Bars and clubs: Popular spots for socializing include The Drake Hotel, The Gladstone Hotel, and The Rex Hotel Jazz & Blues Bar.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"mistralai/mistral-7b-instruct:free\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You answer all questions using 5 short bullet points or less.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are some places, events, or communities to meet people in Toronto?\"}\n",
    "]\n",
    "\n",
    "timer.reset()\n",
    "response = await client.achat(model=model_id, messages=messages)\n",
    "_ = timer.get_elapsed(verbose=True)\n",
    "\n",
    "print()\n",
    "client.print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabe7899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'gen-1756712728-JdPofKFku3x6CvW4neo5',\n",
       " 'provider': 'DeepInfra',\n",
       " 'model': 'mistralai/mistral-7b-instruct:free',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1756712728,\n",
       " 'choices': [{'logprobs': None,\n",
       "   'finish_reason': 'stop',\n",
       "   'native_finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': ' 1. Kensington Market: Vibrant, eclectic neighborhood with unique shops, street performers, and cultural food choices.\\n2. Parks: High Park, Trinity Bellwoods Park, andAllan Gardens offer a casual setting for socializing.\\n3. Meetup.com: Various groups for interests such as sports, hobbies, and networking meet regularly.\\n4. Toronto Public Library: Attend free events, programs, and workshops.\\n5. Bars and clubs: Popular spots for socializing include The Drake Hotel, The Gladstone Hotel, and The Rex Hotel Jazz & Blues Bar.',\n",
       "    'refusal': None,\n",
       "    'reasoning': None}}],\n",
       " 'usage': {'prompt_tokens': 34,\n",
       "  'completion_tokens': 135,\n",
       "  'total_tokens': 169,\n",
       "  'prompt_tokens_details': None}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe22730",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m timer.reset()\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m asyncio.as_completed(futures):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     city, response = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m===== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m =====\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m     client.print_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:630\u001b[39m, in \u001b[36m_AsCompletedIterator._wait_for_one\u001b[39m\u001b[34m(self, resolve)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wait_for_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, resolve=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    627\u001b[39m     \u001b[38;5;66;03m# Wait for the next future to be done and return it unless resolve is\u001b[39;00m\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# set, in which case return either the result of the future or raise\u001b[39;00m\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# an exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     f = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._done.get()\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    632\u001b[39m         \u001b[38;5;66;03m# Dummy value from _handle_timeout().\u001b[39;00m\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/queues.py:186\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28mself\u001b[39m._getters.append(getter)\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    188\u001b[39m     getter.cancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "cities = [\n",
    "    \"Toronto\",\n",
    "    \"New York\",\n",
    "    \"Montreal\",\n",
    "    \"Mexico City\",\n",
    "    \"Paris\",\n",
    "    \"Barcelona\",\n",
    "    \"Hong Kong\",\n",
    "    \"Tokyo\",\n",
    "    \"Singapore\"\n",
    "]\n",
    "\n",
    "async def get_activities_for_city(city: str) -> tuple[str, dict]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer all questions using 5 short bullet points or less.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"What are some places, events, or communities to meet people in {city}?\"}\n",
    "    ]\n",
    "    return city, await client.achat(model=model_id, messages=messages, reasoning={\"enabled\": False})\n",
    "\n",
    "futures = [get_activities_for_city(city) for city in cities]\n",
    "\n",
    "timer.reset()\n",
    "for future in asyncio.as_completed(futures):\n",
    "    city, response = await future\n",
    "    print(f\"===== {city.upper()} =====\")\n",
    "    client.print_response(response)\n",
    "    print(\"\")\n",
    "_ = timer.get_elapsed(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3684a02",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe185e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c22e9ce",
   "metadata": {},
   "source": [
    "#### Provider prompt caching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dfbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "\n",
      "Call me Ishmael. Some years ago—never mind how long precisely—having\n",
      "little or no money in my purse, and nothing particular to interest me\n",
      "on shore, I thought I would sail ab\n",
      "\n",
      "...\n",
      "\n",
      "ime of his God?”\n",
      "\n",
      "He said no more, but slowly waving a benediction, covered his face with\n",
      "his hands, and so remained kneeling, till all the people had departed,\n",
      "and he was left alone in the place.\n",
      "\n",
      "102580 characters\n",
      "25487 tokens\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import tiktoken\n",
    "\n",
    "very_long_text = requests.get(\"https://www.gutenberg.org/ebooks/2701.txt.utf-8\", timeout=60).text\n",
    "\n",
    "# crude: extract Chapter 1 only\n",
    "first_chapters_pattern = r'(CHAPTER 1\\..*?)CHAPTER 10.'\n",
    "matches = re.findall(first_chapters_pattern, very_long_text, re.DOTALL | re.IGNORECASE)\n",
    "very_long_text = matches[1].strip()\n",
    "\n",
    "print(f\"{very_long_text[:200]}\\n\\n...\\n\\n{very_long_text[-200:]}\", end=\"\\n\\n\")\n",
    "print(f\"{len(very_long_text)} characters\")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = enc.encode(very_long_text)\n",
    "print(f\"{len(tokens)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719137d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the provided text:\n",
      "\n",
      "*   **The narrator, Ishmael, feels a deep compulsion to go to sea** when he experiences existential dread and dissatisfaction with life on land.\n",
      "*   **He arrives in New Bedford seeking passage on a Nantucket ship**, encountering a seedy inn called \"The Spouter Inn\" and its peculiar landlord.\n",
      "*   **Ishmael is forced to share a room with an exotic harpooneer named Queequeg**, initially apprehensive due to Queequeg's appearance and rumored cannibalism.\n",
      "*   **Despite his fears, Ishmael finds Queequeg to be a fundamentally decent and polite individual**, and they share a surprisingly peaceful night and breakfast together.\n",
      "*   **The narrative explores themes of fate, man's relationship with nature and the divine, and the harsh realities of the whaling life**, even touching upon religious sermons that reflect these ideas.\n",
      "\n",
      "2.22 seconds elapsed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'gen-1756712623-Z5ZjkcGyBAr4Skr3ILJu',\n",
       " 'provider': 'Google',\n",
       " 'model': 'google/gemini-2.5-flash-lite',\n",
       " 'object': 'chat.completion.chunk',\n",
       " 'created': 1756712623,\n",
       " 'choices': [{'index': 0,\n",
       "   'delta': {'role': 'assistant', 'content': ''},\n",
       "   'finish_reason': None,\n",
       "   'native_finish_reason': None,\n",
       "   'logprobs': None}],\n",
       " 'usage': {'prompt_tokens': 26545,\n",
       "  'completion_tokens': 190,\n",
       "  'total_tokens': 26735,\n",
       "  'cost': 0.0027305,\n",
       "  'is_byok': False,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'cost_details': {'upstream_inference_cost': None,\n",
       "   'upstream_inference_prompt_cost': 0.0026545,\n",
       "   'upstream_inference_completions_cost': 7.6e-05},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0, 'image_tokens': 0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model_id = \"openai/gpt-4o-mini\"\n",
    "system_message = (\n",
    "    f\"The time now is {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\"\n",
    "    \"Your job is to summarize the text provided by the user in 5 bullet points or less.\"\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": very_long_text}\n",
    "]\n",
    "\n",
    "timer.reset()\n",
    "stream = client.chat(model=model_id, messages=messages, usage={\"include\": True}, stream=True, verbose=True)\n",
    "chunks = list(stream)\n",
    "\n",
    "print()\n",
    "_ = timer.get_elapsed(verbose=True)\n",
    "print()\n",
    "\n",
    "display(chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Ishmael decides to go to sea to escape his melancholy and find adventure, specifically choosing a whaling voyage.\n",
      "* He arrives in New Bedford, a whaling hub, and seeks lodging, encountering various inns before settling on the \"Spouter Inn.\"\n",
      "* Ishmael is forced to share a bed with an unseen harpooneer, leading to growing apprehension and a comical confrontation with the landlord.\n",
      "* He eventually meets Queequeg, a heavily tattooed \"savage\" who engages in pagan rituals with a small idol and a tomahawk-pipe. Despite initial fear, Ishmael finds an unexpected respect for Queequeg.\n",
      "* The narrative shifts to Father Mapple's sermon in the Whaleman's Chapel, where he delivers a powerful discourse on Jonah's disobedience, repentance, and God's omnipresent power, urging his congregation, and himself, to preach truth regardless of personal cost.\n",
      "\n",
      "2.17 seconds elapsed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'gen-1756712497-1f4gM9lwzE6Hbw0m0BSF',\n",
       " 'provider': 'Google AI Studio',\n",
       " 'model': 'google/gemini-2.5-flash-image-preview:free',\n",
       " 'object': 'chat.completion.chunk',\n",
       " 'created': 1756712497,\n",
       " 'choices': [{'index': 0,\n",
       "   'delta': {'role': 'assistant', 'content': ''},\n",
       "   'finish_reason': None,\n",
       "   'native_finish_reason': None,\n",
       "   'logprobs': None}],\n",
       " 'usage': {'prompt_tokens': 27047,\n",
       "  'completion_tokens': 186,\n",
       "  'total_tokens': 27233,\n",
       "  'cost': 0,\n",
       "  'is_byok': False,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'cost_details': {'upstream_inference_cost': None,\n",
       "   'upstream_inference_prompt_cost': 0,\n",
       "   'upstream_inference_completions_cost': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0, 'image_tokens': 0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timer.reset()\n",
    "stream = client.chat(model=model_id, messages=messages, usage={\"include\": True}, stream=True, verbose=True)\n",
    "chunks = list(stream)\n",
    "\n",
    "print()\n",
    "_ = timer.get_elapsed(verbose=True)\n",
    "print()\n",
    "\n",
    "display(chunks[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
